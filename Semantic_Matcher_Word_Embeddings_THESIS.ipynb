{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Matcher_Word_Embeddings_THESIS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X6Qi9D_SPEH",
        "colab_type": "text"
      },
      "source": [
        "##Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YL5uPKwmKj2",
        "colab_type": "code",
        "outputId": "67fb575d-1feb-4dbf-9aa7-f2c9b2f1fbb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "#Install module wget for the first time\n",
        "!pip install wget\n",
        "!pip install patool\n",
        "import wget\n",
        "import os, patoolib, numpy as np, math, scipy, re, pandas as pd,csv\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.util import ngrams\n",
        "from numpy import hstack\n",
        "from fnmatch import fnmatch\n",
        "from itertools import product, combinations, zip_longest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=dc9b83f594188f61ed7cf6917643797db5202e90b12ebb6f0474461ddac24f47\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_z6H9MbLlqJ",
        "colab_type": "code",
        "outputId": "ee32c636-5c8c-4bef-fdc5-2410e6c37c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List data_batch files in the root.\n",
        "filelist = drive.ListFile({'q': \"'1k1k42wIe0fMC6l_bkIAZOiVELloEyHis' in parents and trashed=false\"}).GetList() #https://drive.google.com/open?id=1k1k42wIe0fMC6l_bkIAZOiVELloEyHis\n",
        "for file in filelist:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 852kB/s eta 0:00:02\r\u001b[K     |█                               | 30kB 1.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 840kB/s eta 0:00:02\r\u001b[K     |█▋                              | 51kB 1.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 1.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 1.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 1.7MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 1.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 1.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 1.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 1.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 1.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 1.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "title Semantic_Matcher_Word_Embeddings_THESIS.ipynb, id 1qfaCbJMUiU_o15ILY0AsM3DeqFQtCrLS\n",
            "title pyenchant.tar.gz, id 195xxlrclF2xZe8lWWeoQHXW9t4Rr9HWd\n",
            "title GoogleNews-vectors-negative300.bin.gz, id 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVrOLjcxh4zF",
        "colab_type": "text"
      },
      "source": [
        "##WORD2VEC MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRYdABf5MH2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading a file into COLAB from Google Drive that have been uploaded in Google Drive\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '0B7XkCwpI5KDYNlNUTTlSS21pQmM'   #pyenchant-2.0.0.tar.gz, id 195xxlrclF2xZe8lWWeoQHXW9t4Rr9HWd\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "#Storing the downloaded object into a File.\n",
        "downloaded.GetContentFile('GoogleNews-vectors-negative300.bin.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWe-35p7NUAD",
        "colab_type": "code",
        "outputId": "26fe04d3-fd15-44b0-822c-6241f77153e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#To download Google's trained Word2Vec model.\n",
        "#wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
        "\n",
        "#Unzipping the gunzip\n",
        "patoolib.extract_archive(\"GoogleNews-vectors-negative300.bin.gz\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting GoogleNews-vectors-negative300.bin.gz ...\n",
            "patool: running /usr/bin/7z e -o./Unpack_dymqkm2i -- GoogleNews-vectors-negative300.bin.gz\n",
            "patool: ... GoogleNews-vectors-negative300.bin.gz extracted to `GoogleNews-vectors-negative300.bin'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GoogleNews-vectors-negative300.bin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny7_UHytmyql",
        "colab_type": "code",
        "outputId": "fc5157ca-d711-4b2a-b549-b9f294427ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(os.listdir('/content'))\n",
        "\n",
        "#To load this pretrained model into memory,\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'adc.json', 'GoogleNews-vectors-negative300.bin.gz', 'GoogleNews-vectors-negative300.bin', 'sample_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNCcsNPTdTBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a7904322-0231-418c-e901-9793932e5615"
      },
      "source": [
        "#To get an embedding of a word for out of vocabulary\n",
        "\n",
        "\n",
        "def generateOOVembeddings(vocab):\n",
        "  st = vocab\n",
        "  best_subset = \"\"\n",
        "  all_words = {st[i:j + i] for j in range(2, len(st)) for i in range(len(st)- j + 1)}\n",
        "  english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
        "  valid_eng_words = list(english_vocab.intersection(all_words))\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  valid_eng_words = ([w for w in valid_eng_words if w not in stop_words])\n",
        "  #print(valid_eng_words)\n",
        "  max = 0\n",
        "  if(len(valid_eng_words) > 1):\n",
        "    for L in range(0, len(valid_eng_words)+1):\n",
        "        \n",
        "        for subset in combinations(valid_eng_words, 2): \n",
        "            \n",
        "            if((subset[0]+subset[1]) == st or (subset[1]+subset[0]) == st):\n",
        "              best_subset = subset\n",
        "        \n",
        "  else:\n",
        "    best_subset = valid_eng_words\n",
        "  \n",
        "  return(cal_Embeddings(best_subset))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.080992356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Ml3idue8C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To get the final embedding after character modelling\n",
        "def cal_Embeddings(best_subset):\n",
        "  addembedd = np.zeros(300)\n",
        "  for var in best_subset:\n",
        "    addembedd = addembedd + model.word_vec(var)\n",
        "  return(addembedd/len(best_subset))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqt2B17kelri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.word_vec(\"city\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAelBtUT22Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_flow_OOV(word):\n",
        "  try:\n",
        "    return model[word]\n",
        "  except:\n",
        "    return generateOOVembeddings(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB9WZDo9TYVt",
        "colab_type": "text"
      },
      "source": [
        "##Similarity Measure of Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frpGxE6d5rLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cosine distance similarity for out of vocabulary words\n",
        "def cosine_distance_vectorized_method(fir1, fir2):  \n",
        "  dot_prod = sum([x*y for (x,y) in zip(fir1, fir2)])\n",
        "  vec1Len = math.sqrt(sum([x*x for x in fir1]))\n",
        "  vec2Len = math.sqrt(sum([x*x for x in fir2]))\n",
        "  return round(dot_prod / (vec1Len * vec2Len) * 100,2)\n",
        "  #print(round(dot_prod / (vec1Len * vec2Len) * 100,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNC3GmPu7Ze1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cosine distance similarity of words having embedding\n",
        "def cosine_distance_wordembedding_method(s1, s2):\n",
        "    vector_1 = np.mean([model[word] for word in preprocess(s1)],axis=0)\n",
        "    vector_2 = np.mean([model[word] for word in preprocess(s2)],axis=0)\n",
        "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
        "    #print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1 -cosine)*100,2),'%')\n",
        "    return round((1 -cosine)*100,2)\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QYzPOSOvO0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(raw_text):\n",
        "\n",
        "    # keep only words\n",
        "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
        "\n",
        "    # convert to lower case and split \n",
        "    words = letters_only_text.lower().split()\n",
        "    # remove stopwords\n",
        "    stopword_set = set(stopwords.words(\"english\"))\n",
        "    cleaned_words = set([w for w in words if w not in stopword_set])\n",
        "    return cleaned_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf3mk06NT0EO",
        "colab_type": "text"
      },
      "source": [
        "##Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCXZ6nwbhssl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(os.listdir('/content'))\n",
        "items = os.listdir('/content')\n",
        "for file in items:\n",
        "  # To fetch all .tsv files\n",
        "  if fnmatch(file, '*Event*'):\n",
        "    #print (file)\n",
        "    event = pd.read_csv(file , header=None, sep = '\\t')\n",
        "  elif fnmatch(file, '*Sub*'):\n",
        "    subscription = pd.read_csv(file , header=None, sep = '\\t')\n",
        "  elif fnmatch(file, '*Relevance*'):\n",
        "    relevance_gold = pd.read_csv(file , header=None, sep = '\\t')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sryyab9iUJ4L",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing Relevance Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew0tqvJN-fup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relevance_gold_event = []\n",
        "relevance_gold_sub = []\n",
        "for i in relevance_gold.itertuples():\n",
        "  relevance_gold_event.append(i._2.strip(\"[]\").split(','))\n",
        "  relevance_gold_sub.append(i._1.strip(\"[]\").split(','))\n",
        "  \n",
        "flat_list = [item for sublist in relevance_gold_sub for item in sublist]\n",
        "print(flat_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lj5HhtBURWu",
        "colab_type": "text"
      },
      "source": [
        "## Create Gold Standard Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSQk8OWZ91q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e7421ba-e6d2-4c46-dfd9-08ba4c54d1cb"
      },
      "source": [
        "zipbObj = zip(flat_list, relevance_gold_event)\n",
        " \n",
        "# Create a dictionary from zip object\n",
        "gold_dict = dict(zipbObj)\n",
        "\n",
        "print(gold_dict)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'13-1': ['132-52', ' 132-53', ' 132-50', ' 132-51', ' 132-56', ' 132-57', ' 132-54', ' 132-55', ' 132-49', ' 132-48', ' 132-47', ' 132-11', ' 132-10', ' 132-13', ' 132-12', ' 132-40', ' 132-41', ' 132-42', ' 132-43', ' 132-44', ' 132-45', ' 132-46', ' 132-37', ' 132-36', ' 132-39', ' 132-38', ' 132-8', ' 132-7', ' 132-6', ' 132-5', ' 132-9', ' 132-29', ' 132-4', ' 132-25', ' 132-3', ' 132-26', ' 132-2', ' 132-27', ' 132-1', ' 132-28', ' 132-33', ' 132-32', ' 132-35', ' 132-34', ' 132-31', ' 132-30', ' 132-60', ' 132-65', ' 132-66', ' 132-67', ' 132-18', ' 132-68', ' 132-19', ' 132-61', ' 132-16', ' 132-62', ' 132-17', ' 132-63', ' 132-14', ' 132-64', ' 132-15', ' 132-24', ' 132-23', ' 132-22', ' 132-21', ' 132-59', ' 132-20', ' 132-58'], '63-1': ['5-30', ' 5-31', ' 5-32', ' 5-37', ' 5-38', ' 5-39', ' 5-33', ' 5-34', ' 5-35', ' 5-36', ' 5-20', ' 5-21', ' 5-28', ' 5-29', ' 5-26', ' 5-27', ' 5-24', ' 5-25', ' 5-22', ' 5-23', ' 5-67', ' 5-66', ' 5-68', ' 5-19', ' 5-63', ' 5-62', ' 5-65', ' 5-64', ' 5-61', ' 5-60', ' 5-4', ' 5-5', ' 5-6', ' 5-7', ' 5-1', ' 5-2', ' 5-3', ' 5-10', ' 5-11', ' 5-12', ' 5-13', ' 5-14', ' 5-15', ' 5-16', ' 5-17', ' 5-18', ' 5-58', ' 5-57', ' 5-56', ' 5-55', ' 5-59', ' 5-50', ' 5-54', ' 5-53', ' 5-52', ' 5-51', ' 5-45', ' 5-44', ' 5-47', ' 5-46', ' 5-49', ' 5-48', ' 5-41', ' 5-40', ' 5-9', ' 5-43', ' 5-8', ' 5-42']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT6_uaF3hCWZ",
        "colab_type": "text"
      },
      "source": [
        "## Event Types & Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF_x7hNQ2o_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using a itertuples()  \n",
        "event_types_prop = []\n",
        "for i in event.itertuples(): \n",
        "    event_values = i._2.strip(\"{}\").split(',')\n",
        "    event_types_prop.append([i.split('=')[0] for i in event_values])\n",
        "    #print(event_values)\n",
        "    #print(event_values[::2])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qd2fS2bkbiM",
        "colab_type": "text"
      },
      "source": [
        "##Subscription Types & Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW6FWwDikaVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using a itertuples()  \n",
        "subscription_types_prop = []\n",
        "for i in subscription.itertuples(): \n",
        "    subscription_values = i._2.strip(\"{}\").split(',')\n",
        "    subscription_types_prop.append([i.split('~')[0] for i in subscription_values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfPjB602bnfP",
        "colab_type": "text"
      },
      "source": [
        "##Event Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deqPCnpbbmT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using a itertuples()  \n",
        "event_value = []\n",
        "for i in event.itertuples(): \n",
        "    event_values = i._2.strip(\"{}\").split(',')\n",
        "    event_value.append([i.split('=')[1] for i in event_values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czufyUqPfVtE",
        "colab_type": "text"
      },
      "source": [
        "##Subscription Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS6OXQCufbHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using a itertuples()  \n",
        "subscription_value = []\n",
        "for i in subscription.itertuples(): \n",
        "    subscription_values = i._2.strip(\"{}\").split(',')\n",
        "    sec = [i.split('~')[1] for i in subscription_values]\n",
        "    subscription_value.append([i.split('=')[1] for i in sec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ouPH5L0Ub3c",
        "colab_type": "text"
      },
      "source": [
        "##Event Matcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsLYcjtXyaxK",
        "colab_type": "code",
        "outputId": "e152b65c-fd7d-4b01-8a8d-023f3f70fbca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "word2vecDict = defaultdict(list)\n",
        "#word2vecDict = {}\n",
        "for i in event.itertuples():\n",
        "    #print(i)\n",
        "    event_types_prop = []\n",
        "    event_value = []\n",
        "    event_values = i._2.strip(\"{}\").split(',')\n",
        "    event_types_prop.append([i.split('=')[0] for i in event_values])\n",
        "    event_value.append([i.split('=')[1] for i in event_values])\n",
        "    \n",
        "    for j in subscription.itertuples():\n",
        "        subscription_types_prop = []\n",
        "        subscription_value = []\n",
        "        subscription_values = j._2.strip(\"{}\").split(',')\n",
        "        subscription_types_prop.append([i.split('~')[0] for i in subscription_values])\n",
        "        sec = [i.split('~')[1] for i in subscription_values]\n",
        "        subscription_value.append([i.split('=')[1] for i in sec])\n",
        "        \n",
        "        for slist in subscription_types_prop:\n",
        "          for elist in event_types_prop:\n",
        "            dist = 0\n",
        "            for a, b in product(slist, elist):  \n",
        "              try:\n",
        "                cos_dist = cosine_distance_wordembedding_method(a,b)\n",
        "                \n",
        "                if(cos_dist > 65 ):\n",
        "                  \n",
        "                  dist = dist + cos_dist\n",
        "              except:\n",
        "                event_embedding = np.mean([handle_flow_OOV(word) for word in preprocess(b)],axis=0)\n",
        "                try:\n",
        "                  sub_embedding = np.array(model.word_vec(a))\n",
        "                except:\n",
        "                  sub_embedding = np.mean([handle_flow_OOV(word) for word in preprocess(a)],axis=0)\n",
        "                cos_dist_mod = cosine_distance_vectorized_method(event_embedding, sub_embedding)\n",
        "                #print(a,b,cos_dist_mod)\n",
        "                if(cos_dist_mod > 25):\n",
        "                  #print(a,b, cos_dist_mod)\n",
        "                  dist = dist + cos_dist_mod\n",
        "                  \n",
        "        if(dist > 100):\n",
        "          #print(\"================\",dist)\n",
        "          for slist in subscription_value:\n",
        "            for elist in event_value:\n",
        "              final_dist = 0\n",
        "              for a,b in product(slist, elist):\n",
        "                try:\n",
        "                  cos_dist = cosine_distance_wordembedding_method(a,b)\n",
        "                  if(cos_dist > 80 ):\n",
        "                    #print(a,b, cos_dist)\n",
        "                    final_dist = final_dist + cos_dist\n",
        "                except:\n",
        "                  #print(\"hello\")\n",
        "                  event_embedding = np.mean([handle_flow_OOV(word) for word in preprocess(b)],axis=0)\n",
        "                  try:\n",
        "                    sub_embedding = np.array(model.word_vec(a))\n",
        "                  except:\n",
        "                    sub_embedding = np.mean([handle_flow_OOV(word) for word in preprocess(a)],axis=0)\n",
        "                  cos_dist_mod = cosine_distance_vectorized_method(event_embedding, sub_embedding)\n",
        "                  if(cos_dist_mod > 25):\n",
        "                    final_dist = final_dist + cos_dist_mod\n",
        "              #print(\"==========\", final_dist)\n",
        "          if(final_dist >= 350):\n",
        "            \n",
        "            word2vecDict[j._1].append(i._1)\n",
        "            \n",
        "            \n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except ImportError:  # python 3.x\n",
        "    import pickle\n",
        "\n",
        "with open('word2vecDict', 'wb') as fp:\n",
        "    pickle.dump(word2vecDict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O68IVBSqUlS3",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WB01F85pnje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_each_record = 0\n",
        "acc_each_rec = 0\n",
        "prec_each_rec = 0\n",
        "recall_each_rec = 0\n",
        "f1_scr_each_rec = 0\n",
        "  \n",
        "for k in gold_dict.keys() & word2vecDict.keys():\n",
        "    #print(gold_dict[k], \":\", word2vecDict[k])\n",
        "    a = gold_dict[k]\n",
        "    b = word2vecDict[k]\n",
        "    count = 0\n",
        "    correct = 0\n",
        "    print(len(a))\n",
        "    print(len(b))\n",
        "    a = list(map(str.strip, a))\n",
        "    b = list(map(str.strip, b))\n",
        "    tp_tn = sum(el in a for el in b)\n",
        "    fn = get_false_negatives(a, b)\n",
        "    fp = get_false_positives(a, b)\n",
        "    acc_each_rec = acc_each_rec + (tp_tn/(tp_tn + fp + fn))\n",
        "    prec_each_rec = prec_each_rec + (tp_tn/ (tp_tn + fp))\n",
        "    recall_each_rec = recall_each_rec + (tp_tn/ (fn + tp_tn))\n",
        "    f1_scr_each_rec = (2 * prec_each_rec * recall_each_rec)/(prec_each_rec + recall_each_rec)\n",
        "    \n",
        "    for i in range(len(a)):\n",
        "      for j in range(len(b)):\n",
        "        if(a[i].strip() == b[j]):\n",
        "          correct+=1\n",
        "    \n",
        "    if (len(a) > len(b)):\n",
        "      acc_each_record += correct/len(a)\n",
        "    else:\n",
        "      acc_each_record += correct/len(b)\n",
        "    #print(sum(1 for x,y in zip(a,b) if x.strip() == y) / len(a))\n",
        "\n",
        "print(\"Acurracy of the system is :\", acc_each_rec/len(gold_dict.keys())*100)\n",
        "print(\"Precision of the system is :\", prec_each_rec/len(gold_dict.keys())*100)\n",
        "print(\"Recall of the system is :\", recall_each_rec/len(gold_dict.keys())*100)\n",
        "print(\"F1 Score of the system is :\", f1_scr_each_rec/len(gold_dict.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWNZ3J5ZIU7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_false_negatives(actual, pred):\n",
        "  cnt_fn = 0\n",
        "  #len(list(set(list1) ^ set(list2)))\n",
        "  for i in range(len(actual)):\n",
        "    if(actual[i] not in pred):\n",
        "      cnt_fn += 1\n",
        "  return(cnt_fn)\n",
        "\n",
        "def get_false_positives(actual, pred):\n",
        "  cnt_fp = 0\n",
        "  for i in range(len(pred)):\n",
        "    if(pred[i] not in actual):\n",
        "      cnt_fp += 1\n",
        "  return(cnt_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgFrM4BFU1DD",
        "colab_type": "text"
      },
      "source": [
        "##Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjjyscsyDo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_closestwords_tsnescatterplot_word(model, word):\n",
        "    \n",
        "    arr = np.empty((0,300), dtype='f')\n",
        "    word_labels = [word]\n",
        "\n",
        "    # get close words\n",
        "    close_words = model.similar_by_word(word)\n",
        "    \n",
        "    # add the vector for each of the closest words to the array\n",
        "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model[wrd_score[0]]\n",
        "        word_labels.append(wrd_score[0])\n",
        "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
        "        \n",
        "    # find tsne coords for 2 dimensions\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "    np.set_printoptions(suppress=True)\n",
        "    Y = tsne.fit_transform(arr)\n",
        "\n",
        "    x_coords = Y[:, 0]\n",
        "    y_coords = Y[:, 1]\n",
        "    # display scatter plot\n",
        "    plt.scatter(x_coords, y_coords)\n",
        "\n",
        "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
        "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
        "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
        "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
        "    plt.savefig('word2vec_plot.png')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOGv_XCTyekw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "573a29ff-4956-41af-f276-6b79dd5905b2"
      },
      "source": [
        "display_closestwords_tsnescatterplot_word(model, 'car')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEACAYAAACUMoD1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}